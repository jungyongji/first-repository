{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "594e62bd",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0d61e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1651d4",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b309e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e50f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 118964\n",
      ">> Is this enough money?\t¿Es esto suficiente dinero?\n",
      ">> Please choose wisely.\tPor favor, escoja sabiamente.\n",
      ">> How annoying!\t¡No hay quién lo aguante!\n",
      ">> Are they busy?\t¿Están ocupados?\n",
      ">> I've corrected the mistake.\tCorregí el error.\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.dirname(zip_path)+\"/spa-eng/spa.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    spa_eng_sentences = f.read().splitlines()\n",
    "\n",
    "spa_eng_sentences = list(set(spa_eng_sentences)) \n",
    "total_sentence_count = len(spa_eng_sentences)\n",
    "print(\"Example:\", total_sentence_count)\n",
    "\n",
    "for sen in spa_eng_sentences[0:100][::20]: \n",
    "    print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64481634",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976fbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d17ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_eng_sentences = list(map(preprocess_sentence, spa_eng_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f829311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size:  594\n",
      "\n",
      "\n",
      "Train Example: 118370\n",
      ">> is this enough money?\t¿es esto suficiente dinero?\n",
      ">> please choose wisely.\tpor favor, escoja sabiamente.\n",
      ">> how annoying!\t¡no hay quién lo aguante!\n",
      ">> are they busy?\t¿están ocupados?\n",
      ">> i've corrected the mistake.\tcorregí el error.\n",
      "\n",
      "\n",
      "Test Example: 594\n",
      ">> how long are you going to stay here?\t¿cuánto tiempo vas a quedarte aquí?\n",
      ">> muammar kaddafi escaped unharmed.\tmuamar alqadaafi escapó ileso.\n",
      ">> his family moved into a new house in the suburbs.\tsu familia se mudó a una casa nueva en las afueras de la ciudad.\n",
      ">> tom thought only of mary.\ttom solo pensó en mary.\n",
      ">> i'm very busy so don't count on me.\testoy muy ocupada, así que no cuentes conmigo.\n"
     ]
    }
   ],
   "source": [
    "test_sentence_count = total_sentence_count // 200\n",
    "print(\"Test Size: \", test_sentence_count)\n",
    "print(\"\\n\")\n",
    "\n",
    "train_spa_eng_sentences = spa_eng_sentences[:-test_sentence_count]\n",
    "test_spa_eng_sentences = spa_eng_sentences[-test_sentence_count:]\n",
    "print(\"Train Example:\", len(train_spa_eng_sentences))\n",
    "for sen in train_spa_eng_sentences[0:100][::20]: \n",
    "    print(\">>\", sen)\n",
    "print(\"\\n\")\n",
    "print(\"Test Example:\", len(test_spa_eng_sentences))\n",
    "for sen in test_spa_eng_sentences[0:100][::20]: \n",
    "    print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead51f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spa_eng_sentences(spa_eng_sentences):\n",
    "    spa_sentences = []\n",
    "    eng_sentences = []\n",
    "    for spa_eng_sentence in tqdm(spa_eng_sentences):\n",
    "        eng_sentence, spa_sentence = spa_eng_sentence.split('\\t')\n",
    "        spa_sentences.append(spa_sentence)\n",
    "        eng_sentences.append(eng_sentence)\n",
    "    return eng_sentences, spa_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf97ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e35c4b0be29498a9b11e25a5ea60a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118370\n",
      "is this enough money?\n",
      "\n",
      "\n",
      "118370\n",
      "¿es esto suficiente dinero?\n"
     ]
    }
   ],
   "source": [
    "train_eng_sentences, train_spa_sentences = split_spa_eng_sentences(train_spa_eng_sentences)\n",
    "print(len(train_eng_sentences))\n",
    "print(train_eng_sentences[0])\n",
    "print('\\n')\n",
    "print(len(train_spa_sentences))\n",
    "print(train_spa_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653bf0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ddd66deef40d28bca64d018471ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "how long are you going to stay here?\n",
      "\n",
      "\n",
      "594\n",
      "¿cuánto tiempo vas a quedarte aquí?\n"
     ]
    }
   ],
   "source": [
    "test_eng_sentences, test_spa_sentences = split_spa_eng_sentences(test_spa_eng_sentences)\n",
    "print(len(test_eng_sentences))\n",
    "print(test_eng_sentences[0])\n",
    "print('\\n')\n",
    "print(len(test_spa_sentences))\n",
    "print(test_spa_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951642d8",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96253e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenizer(corpus,\n",
    "                       vocab_size,\n",
    "                       lang=\"spa-eng\",\n",
    "                       pad_id=0,   # pad token의 일련번호\n",
    "                       bos_id=1,  # 문장의 시작을 의미하는 bos token(<s>)의 일련번호\n",
    "                       eos_id=2,  # 문장의 끝을 의미하는 eos token(</s>)의 일련번호\n",
    "                       unk_id=3):   # unk token의 일련번호\n",
    "    file = \"./%s_corpus.txt\" % lang\n",
    "    model = \"%s_spm\" % lang\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        for row in corpus: f.write(str(row) + '\\n')\n",
    "\n",
    "    import sentencepiece as spm\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input=./%s --model_prefix=%s --vocab_size=%d'\\\n",
    "        % (file, model, vocab_size) + \\\n",
    "        '--pad_id==%d --bos_id=%d --eos_id=%d --unk_id=%d'\\\n",
    "        % (pad_id, bos_id, eos_id, unk_id)\n",
    "    )\n",
    "\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load('%s.model' % model)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dae17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=././spa-eng_corpus.txt --model_prefix=spa-eng_spm --vocab_size=20000--pad_id==0 --bos_id=1 --eos_id=2 --unk_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ././spa-eng_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spa-eng_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ././spa-eng_corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 236740 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=7877169\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9544% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=43\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999544\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 236740 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 110147 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 236740\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 62399\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 62399 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=35518 obj=10.7522 num_tokens=118493 num_tokens/piece=3.33614\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=28132 obj=8.52336 num_tokens=118966 num_tokens/piece=4.22885\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21998 obj=8.47786 num_tokens=125704 num_tokens/piece=5.71434\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21984 obj=8.46364 num_tokens=125765 num_tokens/piece=5.72075\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spa-eng_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spa-eng_spm.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "tokenizer = generate_tokenizer(train_eng_sentences + train_spa_sentences, VOCAB_SIZE, 'spa-eng')\n",
    "tokenizer.set_encode_extra_options(\"bos:eos\")  # 문장 양 끝에 <s> , </s> 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9810a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(sentences, tokenizer):\n",
    "    corpus = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokens = tokenizer.encode_as_ids(sentence)\n",
    "        corpus.append(tokens)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a797183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd851d443dff40ff9bca0950d55dcaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96361b4b6dd54c64b5fb4db8df43c55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eng_corpus = make_corpus(train_eng_sentences, tokenizer)\n",
    "spa_corpus = make_corpus(train_spa_sentences, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f0f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is this enough money?\n",
      "[1, 21, 41, 475, 203, 8, 2]\n",
      "\n",
      "\n",
      "¿es esto suficiente dinero?\n",
      "[1, 18, 184, 139, 582, 209, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "print(train_eng_sentences[0])\n",
    "print(eng_corpus[0])\n",
    "print('\\n')\n",
    "print(train_spa_sentences[0])\n",
    "print(spa_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec8b0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "enc_ndarray = tf.keras.preprocessing.sequence.pad_sequences(eng_corpus, maxlen=MAX_LEN, padding='post')\n",
    "dec_ndarray = tf.keras.preprocessing.sequence.pad_sequences(spa_corpus, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b91bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_ndarray, dec_ndarray)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e77de",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73aa34",
   "metadata": {},
   "source": [
    "#### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e8bb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa847c79",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd6c7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f7d4d",
   "metadata": {},
   "source": [
    "#### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beec8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea6785",
   "metadata": {},
   "source": [
    "#### Position-wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203bcad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2aa7b",
   "metadata": {},
   "source": [
    "#### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a650a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e795042",
   "metadata": {},
   "source": [
    "#### Decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e5b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41baf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e37a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7106241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0a2d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\t\t\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "352b431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1f7b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0356a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3840e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5a190",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "974c1936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c5a1966ea7461594e24b7871b5422c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac715da1fd94ceaa5d5ef8d16db8405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860091727eba46c5877fcd332d86de28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    for step, (enc_batch, dec_batch) in enumerate(train_dataset):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_batch,\n",
    "                    dec_batch,\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_bar.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        tqdm_bar.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (step + 1)))\n",
    "        tqdm_bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d09c28",
   "metadata": {},
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc51554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문: ['많', '은', '자연어', '처리', '연구자', '들', '이', '트랜스포머', '를', '선호', '한다']\n",
      "번역문: ['적', '은', '자연어', '학', '개발자', '들', '가', '트랜스포머', '을', '선호', '한다', '요']\n",
      "BLEU Score: 8.190757052088229e-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# 아래 두 문장을 바꿔가며 테스트 해보세요\n",
    "reference = \"많 은 자연어 처리 연구자 들 이 트랜스포머 를 선호 한다\".split()\n",
    "candidate = \"적 은 자연어 학 개발자 들 가 트랜스포머 을 선호 한다 요\".split()\n",
    "\n",
    "print(\"원문:\", reference)\n",
    "print(\"번역문:\", candidate)\n",
    "print(\"BLEU Score:\", sentence_bleu([reference], candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c920f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram: 0.5\n",
      "2-gram: 0.18181818181818182\n",
      "3-gram: 2.2250738585072626e-308\n",
      "4-gram: 2.2250738585072626e-308\n"
     ]
    }
   ],
   "source": [
    "print(\"1-gram:\", sentence_bleu([reference], candidate, weights=[1, 0, 0, 0]))\n",
    "print(\"2-gram:\", sentence_bleu([reference], candidate, weights=[0, 1, 0, 0]))\n",
    "print(\"3-gram:\", sentence_bleu([reference], candidate, weights=[0, 0, 1, 0]))\n",
    "print(\"4-gram:\", sentence_bleu([reference], candidate, weights=[0, 0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd92e8",
   "metadata": {},
   "source": [
    "#### SmoothingFunction()으로 BLEU Score 보정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83bac322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.5\n",
      "BLEU-2: 0.18181818181818182\n",
      "BLEU-3: 0.010000000000000004\n",
      "BLEU-4: 0.011111111111111112\n",
      "\n",
      "BLEU-Total: 0.05637560315259291\n"
     ]
    }
   ],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                         candidate,\n",
    "                         weights=weights,\n",
    "                         smoothing_function=SmoothingFunction().method1)  # smoothing_function 적용\n",
    "\n",
    "print(\"BLEU-1:\", calculate_bleu(reference, candidate, weights=[1, 0, 0, 0]))\n",
    "print(\"BLEU-2:\", calculate_bleu(reference, candidate, weights=[0, 1, 0, 0]))\n",
    "print(\"BLEU-3:\", calculate_bleu(reference, candidate, weights=[0, 0, 1, 0]))\n",
    "print(\"BLEU-4:\", calculate_bleu(reference, candidate, weights=[0, 0, 0, 1]))\n",
    "\n",
    "print(\"\\nBLEU-Total:\", calculate_bleu(reference, candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866de2e",
   "metadata": {},
   "source": [
    "## 번역 성능 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f13ff5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def translate(tokens, model, src_tokenizer, tgt_tokenizer):\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=MAX_LEN,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)   \n",
    "    for i in range(MAX_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)  \n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db024ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, src_tokenizer, tgt_tokenizer, verbose=True):\n",
    "    src_tokens = src_tokenizer.encode_as_ids(src_sentence)\n",
    "    tgt_tokens = tgt_tokenizer.encode_as_ids(tgt_sentence)\n",
    "\n",
    "    if (len(src_tokens) > MAX_LEN): return None\n",
    "    if (len(tgt_tokens) > MAX_LEN): return None\n",
    "\n",
    "    reference = tgt_sentence.split()\n",
    "    candidate = translate(src_tokens, model, src_tokenizer, tgt_tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Real: \", reference)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe0b0e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  how long are you going to stay here?\n",
      "Model Prediction:  ['¿cuánto', 'se', 'va', 'a', 'quedar', 'aquí?']\n",
      "Real:  ['¿cuánto', 'tiempo', 'vas', 'a', 'quedarte', 'aquí?']\n",
      "Score: 0.053728\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05372849659117709"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스를 바꿔가며 테스트해 보세요\n",
    "test_idx = 0\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 test_eng_sentences[test_idx], \n",
    "                 test_spa_sentences[test_idx], \n",
    "                 tokenizer, \n",
    "                 tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24a447d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentence, src_tokenizer, tgt_tokenizer, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        score = eval_bleu_single(model, src_sentences[idx], tgt_sentence[idx], src_tokenizer, tgt_tokenizer, verbose)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4357c87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe7862e331546cd8e1f0bc18daccdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Sample: 594\n",
      "Total Score: 0.0911819539701506\n"
     ]
    }
   ],
   "source": [
    "eval_bleu(transformer, test_eng_sentences, test_spa_sentences, tokenizer, tokenizer, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f7545",
   "metadata": {},
   "source": [
    "## Beam search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc7e76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoder(prob, beam_size):\n",
    "    sequences = [[[], 1.0]]  # 생성된 문장과 점수를 저장\n",
    "\n",
    "    for tok in prob:\n",
    "        all_candidates = []\n",
    "\n",
    "        for seq, score in sequences:\n",
    "            for idx, p in enumerate(tok): # 각 단어의 확률을 총점에 누적 곱\n",
    "                candidate = [seq + [idx], score * -math.log(-(p-1))]\n",
    "                all_candidates.append(candidate)\n",
    "\n",
    "        ordered = sorted(all_candidates,\n",
    "                         key=lambda tup:tup[1],\n",
    "                         reverse=True) # 총점 순 정렬\n",
    "        sequences = ordered[:beam_size] # Beam Size에 해당하는 문장만 저장 \n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9f25a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "커피 를 가져 도 될 까요? <pad> <pad> <pad> <pad>  // Score: 42.5243\n",
      "커피 를 마셔 도 될 까요? <pad> <pad> <pad> <pad>  // Score: 28.0135\n",
      "마셔 를 가져 도 될 까요? <pad> <pad> <pad> <pad>  // Score: 17.8983\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    0: \"<pad>\",\n",
    "    1: \"까요?\",\n",
    "    2: \"커피\",\n",
    "    3: \"마셔\",\n",
    "    4: \"가져\",\n",
    "    5: \"될\",\n",
    "    6: \"를\",\n",
    "    7: \"한\",\n",
    "    8: \"잔\",\n",
    "    9: \"도\",\n",
    "}\n",
    "\n",
    "prob_seq = [[0.01, 0.01, 0.60, 0.32, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.75, 0.01, 0.01, 0.17],\n",
    "            [0.01, 0.01, 0.01, 0.35, 0.48, 0.10, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.24, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.68],\n",
    "            [0.01, 0.01, 0.12, 0.01, 0.01, 0.80, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.01, 0.81, 0.01, 0.01, 0.01, 0.01, 0.11, 0.01, 0.01, 0.01],\n",
    "            [0.70, 0.22, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
    "            [0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]]\n",
    "\n",
    "prob_seq = np.array(prob_seq)\n",
    "beam_size = 3\n",
    "\n",
    "result = beam_search_decoder(prob_seq, beam_size)\n",
    "\n",
    "for seq, score in result:\n",
    "    sentence = \"\"\n",
    "\n",
    "    for word in seq:\n",
    "        sentence += vocab[word] + \" \"\n",
    "\n",
    "    print(sentence, \"// Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5bdc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(src_ids, tgt_ids, model):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "    generate_masks(src_ids, tgt_ids)\n",
    "\n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "    model(src_ids, \n",
    "            tgt_ids,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask)\n",
    "    \n",
    "    return tf.math.softmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b770ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoder(sentence, \n",
    "                        src_len,\n",
    "                        tgt_len,\n",
    "                        model,\n",
    "                        src_tokenizer,\n",
    "                        tgt_tokenizer,\n",
    "                        beam_size):\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "    \n",
    "    src_in = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                            maxlen=src_len,\n",
    "                                                            padding='post')\n",
    "\n",
    "    pred_cache = np.zeros((beam_size * beam_size, tgt_len), dtype=np.int64)\n",
    "    pred_tmp = np.zeros((beam_size, tgt_len), dtype=np.int64)\n",
    "\n",
    "    eos_flag = np.zeros((beam_size, ), dtype=np.int64)\n",
    "    scores = np.ones((beam_size, ))\n",
    "\n",
    "    pred_tmp[:, 0] = tgt_tokenizer.bos_id()\n",
    "\n",
    "    dec_in = tf.expand_dims(pred_tmp[0, :1], 0)\n",
    "    prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "\n",
    "    for seq_pos in range(1, tgt_len):\n",
    "        score_cache = np.ones((beam_size * beam_size, ))\n",
    "\n",
    "        # init\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            score_cache[cache_pos:cache_pos+beam_size] = scores[branch_idx]\n",
    "            pred_cache[cache_pos:cache_pos+beam_size, :seq_pos] = \\\n",
    "            pred_tmp[branch_idx, :seq_pos]\n",
    "\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            if seq_pos != 1:   # 모든 Branch를 로 시작하는 경우를 방지\n",
    "                dec_in = pred_cache[branch_idx, :seq_pos]\n",
    "                dec_in = tf.expand_dims(dec_in, 0)\n",
    "\n",
    "                prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "\n",
    "            for beam_idx in range(beam_size):\n",
    "                max_idx = np.argmax(prob)\n",
    "\n",
    "                score_cache[cache_pos+beam_idx] *= prob[max_idx]\n",
    "                pred_cache[cache_pos+beam_idx, seq_pos] = max_idx\n",
    "\n",
    "                prob[max_idx] = -1\n",
    "\n",
    "        for beam_idx in range(beam_size):\n",
    "            if eos_flag[beam_idx] == -1: continue\n",
    "\n",
    "            max_idx = np.argmax(score_cache)\n",
    "            prediction = pred_cache[max_idx, :seq_pos+1]\n",
    "\n",
    "            pred_tmp[beam_idx, :seq_pos+1] = prediction\n",
    "            scores[beam_idx] = score_cache[max_idx]\n",
    "            score_cache[max_idx] = -1\n",
    "\n",
    "            if prediction[-1] == tgt_tokenizer.eos_id():\n",
    "                eos_flag[beam_idx] = -1\n",
    "\n",
    "    pred = []\n",
    "    for long_pred in pred_tmp:\n",
    "        zero_idx = long_pred.tolist().index(tgt_tokenizer.eos_id())\n",
    "        short_pred = long_pred[:zero_idx+1]\n",
    "        pred.append(short_pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6a166a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                            candidate,\n",
    "                            weights=weights,\n",
    "                            smoothing_function=SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c7d2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_bleu(reference, ids, tokenizer):\n",
    "    reference = reference.split()\n",
    "\n",
    "    total_score = 0.0\n",
    "    for _id in ids:\n",
    "        candidate = tokenizer.decode_ids(_id.tolist()).split()\n",
    "        score = calculate_bleu(reference, candidate)\n",
    "\n",
    "        print(\"Reference:\", reference)\n",
    "        print(\"Candidate:\", candidate)\n",
    "        print(\"BLEU:\", calculate_bleu(reference, candidate))\n",
    "\n",
    "        total_score += score\n",
    "        \n",
    "    return total_score / len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0aad7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: ['tome', 'este', 'medicamento', 'después', 'de', 'las', 'comidas.']\n",
      "Candidate: ['toma', 'esta', 'medicina', 'después', 'de', 'las', 'comidas', 'después', 'de', 'esta', 'comida', 'después', 'de', 'las', 'comidas?']\n",
      "BLEU: 0.06541868941754436\n",
      "Reference: ['tome', 'este', 'medicamento', 'después', 'de', 'las', 'comidas.']\n",
      "Candidate: ['toma', 'esta', 'medicina', 'después', 'de', 'las', 'comidas', 'después', 'de', 'comer', 'comida', 'después', 'de', 'las', 'comidas?']\n",
      "BLEU: 0.06541868941754436\n",
      "Reference: ['tome', 'este', 'medicamento', 'después', 'de', 'las', 'comidas.']\n",
      "Candidate: ['toma', 'esta', 'medicina', 'después', 'de', 'las', 'comidas', 'después', 'de', 'esta', 'comidas', 'después', 'de', 'las', 'comidas?']\n",
      "BLEU: 0.06541868941754436\n",
      "Reference: ['tome', 'este', 'medicamento', 'después', 'de', 'las', 'comidas.']\n",
      "Candidate: ['toma', 'esta', 'medicina', 'después', 'de', 'las', 'comidas', 'después', 'de', 'los', 'comida', 'después', 'de', 'las', 'comidas?']\n",
      "BLEU: 0.06541868941754436\n",
      "Reference: ['tome', 'este', 'medicamento', 'después', 'de', 'las', 'comidas.']\n",
      "Candidate: ['toma', 'esta', 'medicina', 'después', 'de', 'las', 'comidas', 'después', 'de', 'esta', 'comida', 'después', 'de', 'las', 'comidas', 'después']\n",
      "BLEU: 0.06087895024805787\n",
      "0.06451074158364707\n"
     ]
    }
   ],
   "source": [
    "# 인덱스를 바꿔가며 확인해 보세요\n",
    "test_idx = 2\n",
    "\n",
    "ids = \\\n",
    "beam_search_decoder(test_eng_sentences[test_idx],\n",
    "                    MAX_LEN,\n",
    "                    MAX_LEN,\n",
    "                    transformer,\n",
    "                    tokenizer,\n",
    "                    tokenizer,\n",
    "                    beam_size=5)\n",
    "\n",
    "bleu = beam_bleu(test_spa_sentences[test_idx], ids, tokenizer)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328205be",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e6a9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.0% 368.7/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15a7ffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bananas', 0.6691170930862427),\n",
       " ('mango', 0.5804104208946228),\n",
       " ('pineapple', 0.5492372512817383),\n",
       " ('coconut', 0.5462778806686401),\n",
       " ('papaya', 0.541056752204895),\n",
       " ('fruit', 0.52181077003479),\n",
       " ('growers', 0.4877638816833496),\n",
       " ('nut', 0.48399588465690613),\n",
       " ('peanut', 0.48062023520469666),\n",
       " ('potato', 0.48061180114746094)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72dcf57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: you know ? all you need is attention .\n",
      "To: you know ? all you need is attention , \n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"you know ? all you need is attention .\"\n",
    "sample_tokens = sample_sentence.split()\n",
    "\n",
    "selected_tok = random.choice(sample_tokens)\n",
    "\n",
    "result = \"\"\n",
    "for tok in sample_tokens:\n",
    "    if tok is selected_tok:\n",
    "        result += wv.most_similar(tok)[0][0] + \" \"\n",
    "\n",
    "    else:\n",
    "        result += tok + \" \"\n",
    "\n",
    "print(\"From:\", sample_sentence)\n",
    "print(\"To:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff77d7b",
   "metadata": {},
   "source": [
    "## Lexical Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c434c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    res = \"\"\n",
    "    toks = sentence.split()\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(toks)\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "        \n",
    "    except:   # 단어장에 없는 단어\n",
    "        return None\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok is _from: res += _to + \" \"\n",
    "        else: res += tok + \" \"\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ee25a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ae4c2f207c4f318d53a60b1dbfe622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"how long are 'll going to stay here? \", 'how long are you going to stay here?', \"'d was busy all day. \", 'i was busy all day.', 'take this medical after meals. ', 'take this medicine after meals.', 'there now a church across the street. ', 'there is a church across the street.', 'achille was born where paris in 1908. ', 'achille was born in paris in 1908.']\n"
     ]
    }
   ],
   "source": [
    "new_corpus = []\n",
    "\n",
    "for old_src in tqdm(test_eng_sentences):\n",
    "    new_src = lexical_sub(old_src, wv)\n",
    "    if new_src is not None: \n",
    "        new_corpus.append(new_src)\n",
    "    # Augmentation이 없더라도 원본 문장을 포함시킵니다\n",
    "    new_corpus.append(old_src)\n",
    "\n",
    "print(new_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04120b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b405511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b20b542a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "19dd10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dc8a6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592b722",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b56e87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getenv('HOME')+'/aiffel/transformer_chatbot/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "bfbc2484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path +'/ChatbotData.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53020a07",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8652c215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d0769c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1e29c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:,:2]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e5e2574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡!\n",
      "A : 하루가 또 가네요.\n",
      "\n",
      "Q : 1지망 학교 떨어졌어\n",
      "A : 위로해 드립니다.\n",
      "\n",
      "Q : 3박4일 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : 3박4일 정도 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살이 찌푸려지죠.\n",
      "\n",
      "Q : SD카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SD카드 안돼\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Q : SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n",
      "Q : SNS 시간낭비인데 자꾸 보게됨\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Q :', data['Q'][i])\n",
    "    print('A :', data['A'][i])    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1a8d61de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>가족들과 상의해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>공시 준비 힘들어</td>\n",
       "      <td>잘 될 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>돈 벌고 싶어</td>\n",
       "      <td>많이 벌수록 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>로또 번호 알려줘</td>\n",
       "      <td>알면 제가 하죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>마음이 울적해</td>\n",
       "      <td>거리를 걸어보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>착해서 잘해주는 건지 좋아하는 건지</td>\n",
       "      <td>헷갈린다고 말해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>첫 눈에 반하는게 가능해?</td>\n",
       "      <td>당연히 가능하죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>첫사랑 생각나</td>\n",
       "      <td>지금의 사랑에 충실하세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>커플여행이 나을까 그냥 우리끼리 갈까?</td>\n",
       "      <td>저는 둘이 가는 게 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Q                A\n",
       "196               고양이 키우고 싶어     가족들과 상의해보세요.\n",
       "235                공시 준비 힘들어         잘 될 거예요.\n",
       "1294                 돈 벌고 싶어      많이 벌수록 좋아요.\n",
       "1445               로또 번호 알려줘        알면 제가 하죠.\n",
       "1481                 마음이 울적해       거리를 걸어보세요.\n",
       "...                      ...              ...\n",
       "11642    착해서 잘해주는 건지 좋아하는 건지     헷갈린다고 말해보세요.\n",
       "11649         첫 눈에 반하는게 가능해?        당연히 가능하죠.\n",
       "11658                첫사랑 생각나   지금의 사랑에 충실하세요.\n",
       "11732  커플여행이 나을까 그냥 우리끼리 갈까?  저는 둘이 가는 게 좋아요.\n",
       "11819         훔쳐보는 것도 눈치 보임.    훔쳐보는 거 티나나봐요.\n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['Q'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "dad8c9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가끔 뭐하는지 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가스불 켜놓고 나온거 같아</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.</td>\n",
       "      <td>맘고생 많았어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>화이트데이에 고백할까요?</td>\n",
       "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11809</th>\n",
       "      <td>확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?</td>\n",
       "      <td>그 사람을 위해서는 그러면 안돼요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Q                                    A\n",
       "3                       3박4일 정도 놀러가고 싶다                          여행은 언제나 좋죠.\n",
       "6                               SD카드 안돼                   다시 새로 사는 게 마음 편해요.\n",
       "9                     SNS 시간낭비인데 자꾸 보게됨                        시간을 정하고 해보세요.\n",
       "12                          가끔 뭐하는지 궁금해                        그 사람도 그럴 거예요.\n",
       "18                       가스불 켜놓고 나온거 같아                  빨리 집에 돌아가서 끄고 나오세요.\n",
       "...                                 ...                                  ...\n",
       "11806         혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.                            맘고생 많았어요.\n",
       "11807                     화이트데이에 고백할까요?            선물을 주면서 솔직하고 당당하게 고백해보세요.\n",
       "11809  확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?                  그 사람을 위해서는 그러면 안돼요.\n",
       "11816                 회식하는데 나만 챙겨줘. 썸임?  호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11822                        힘들어서 결혼할까봐                   도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[4044 rows x 2 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['A'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f7250718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 57\n",
      "문장의 평균 길이: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/3564982157.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 265,
       "width": 373
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in questions:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(questions))\n",
    "\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in questions:   # 중복이 제거된 코퍼스 기준\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a34237cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 76\n",
      "문장의 평균 길이: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/3544393292.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 265,
       "width": 373
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in answers:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(answers))\n",
    "\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in answers:   # 중복이 제거된 코퍼스 기준\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a18d8",
   "metadata": {},
   "source": [
    "## Preprocessing and Tokeninzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "50dbc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!가-힣ㄱ-ㅎㅏ-ㅣ0-9]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b7e3c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(row_file):\n",
    "    que_corpus = []\n",
    "    ans_corpus = []\n",
    "    \n",
    "    for i in range(0, len(row_file)):\n",
    "        mecab = Mecab()\n",
    "        \n",
    "        que, ans = row_file.loc[i]\n",
    "        \n",
    "        que = preprocess_sentence(que)\n",
    "        que = mecab.morphs(que)\n",
    "        \n",
    "        ans = preprocess_sentence(ans)\n",
    "        ans = mecab.morphs(ans)\n",
    "        \n",
    "        if len(que) < 40 and len(ans) < 60: # 길이의 75퍼센타일 \n",
    "            if que not in que_corpus:\n",
    "                if ans not in ans_corpus: #소스와 타겟별 중복 검사\n",
    "                    que_corpus.append(que)\n",
    "                    ans_corpus.append(ans)\n",
    "    \n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "92a6ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = build_corpus(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dd899563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', 'ㅠㅠ'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "594eb593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['하루', '가', '또', '가', '네요', '.'],\n",
       " ['위로', '해', '드립니다', '.'],\n",
       " ['여행', '은', '언제나', '좋', '죠', '.'],\n",
       " ['눈살', '이', '찌푸려', '지', '죠', '.'],\n",
       " ['다시', '새로', '사', '는', '게', '마음', '편해요', '.'],\n",
       " ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.'],\n",
       " ['시간', '을', '정하', '고', '해', '보', '세요', '.'],\n",
       " ['자랑', '하', '는', '자리', '니까요', '.'],\n",
       " ['그', '사람', '도', '그럴', '거', '예요', '.'],\n",
       " ['혼자', '를', '즐기', '세요', '.']]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44891e",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5a25e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_bin_path = path + '/ko.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "15791a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(ko_bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "05990d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    toks = sentence\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(toks)\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "\n",
    "    except:   # 단어장에 없는 단어\n",
    "        return sentence\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok is _from: res.append(_to)\n",
    "        else: res.append(tok)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "72d8926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['12', '시', '땡', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e8087068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['12', '시가', '땡', '!']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_sub(temp, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "aa43fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7683\n",
      "7683\n"
     ]
    }
   ],
   "source": [
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0994bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/859389102.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e94c5b86b3846c68976a2e531db1f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7683 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = lexical_sub(que_corpus[i], word2vec)\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "23989986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2512862008.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8e6e5633d94af4bb5aa4e0b6a047cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7683 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = lexical_sub(ans_corpus[i], word2vec)\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "baf98421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/1073649924.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250ec48160214be081a59300a3cad647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7683 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c5aa614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23049\n",
      "23049\n"
     ]
    }
   ],
   "source": [
    "print(len(src_corpus))\n",
    "print(len(tgt_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "579aff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시가', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '살', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '카나'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', 'ㅠㅠ'],\n",
       " ['sns', '시간', '낭비', '인', '것', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해의', '보여'],\n",
       " ['가끔', '궁금', '해의'],\n",
       " ['가끔', '은데', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "69716fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data = []\n",
    "\n",
    "for sen in tgt_corpus:\n",
    "    sen = [\"<start>\"] + sen + [\"<end>\"]\n",
    "    que_data.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "652c80ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '.', '<end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '.', '<end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', '<end>'],\n",
       " ['<start>', '눈살', '이', '찌푸려', '지', '죠', '.', '<end>'],\n",
       " ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '.', '<end>'],\n",
       " ['<start>', '잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.', '<end>'],\n",
       " ['<start>', '시간', '을', '정하', '고', '해', '보', '세요', '.', '<end>'],\n",
       " ['<start>', '자랑', '하', '는', '자리', '니까요', '.', '<end>'],\n",
       " ['<start>', '그', '사람', '도', '그럴', '거', '예요', '.', '<end>'],\n",
       " ['<start>', '혼자', '를', '즐기', '세요', '.', '<end>']]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ccd45",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c0182349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46098"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = que_data + src_corpus\n",
    "\n",
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "22ecafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.concatenate(total_data).tolist()\n",
    "counter = Counter(words)\n",
    "counter = counter.most_common(30000-2)\n",
    "vocab = ['<pad>', '<unk>'] + [key for key, _ in counter]\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9da35a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', '.', '<start>', '<end>', '이', '는', '하', '을', '가']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(word_to_index))\n",
    "sorted(word_to_index, key=word_to_index.get)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b6163558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a2c09073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<unk>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "600a5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d16a8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = vectorize(src_corpus, word_to_index)\n",
    "dec_train = vectorize(que_data, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c89a5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23049\n",
      "23049\n",
      "[2505, 1825, 3274, 107]\n",
      "[3, 273, 9, 142, 9, 43, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_train))\n",
    "print(len(dec_train))\n",
    "print(enc_train[0])\n",
    "print(dec_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ab65f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = keras.preprocessing.sequence.pad_sequences(enc_train,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=40)\n",
    "\n",
    "dec_train = keras.preprocessing.sequence.pad_sequences(dec_train,\n",
    "                                                       value=word_to_index[\"<pad>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21952b8",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "45d51411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0792b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "72c91a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d47f51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "47662dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.dec_self_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "67e0c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "85356b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e7a44b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "1e1519da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0b4c809e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 208,
       "width": 426
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1)Encoder Mask')\n",
    "ax2.set_title('2)Encoder-Decoder Mask')\n",
    "ax3.set_title('3)Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a5e0d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = LearningRateScheduler(512)\n",
    "oprimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "49a5ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=len(enc_train),\n",
    "    tgt_vocab_size=len(dec_train),\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3366a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5efd72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e45e9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace99389",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/4273148178.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58814f0b54c24c658dcd5798cbd58106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b7470798ee419abb34ef9f49490a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520d162d27e9441abb6efd8b314f53c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0635ccd19b74d2f9d3f03650f653c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a43ffa93569407fa04a21486f6b2c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe38c5be9cf446e1ab4b096fa04a8942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99712044bcb0470a99e92203aca2590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3e416",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f61766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, model):\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    pieces = mecab.morphs(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for sen in pieces:\n",
    "        sen= get_encoded_sentence(sen, word_to_index)\n",
    "        tokens.append(sen)\n",
    "    \n",
    "    _input = keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=20)\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([word_to_index[\"<start>\"]], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if word_to_index[\"<end>\"] == predicted_id:\n",
    "            result = get_decoded_sentence(ids, index_to_word)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = get_decoded_sentence(ids, index_to_word)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00013eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ['지루하다, 놀러가고 싶어.',\n",
    "               '오늘 일찍 일어났더니 피곤하다.',\n",
    "               '간만에 여자친구랑 데이트 하기로 했어.',\n",
    "               '집에 있는다는 소리야.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen in sample_text:\n",
    "    print('원문 : ', sen)\n",
    "    print('답변 : ', translate(sen, transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f84237",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385440c",
   "metadata": {},
   "source": [
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?  \n",
    " - **챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.**  \n",
    " \n",
    " \n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?  \n",
    " - **과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.**  \n",
    " \n",
    " \n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?  \n",
    " - **주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a49286",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68728560",
   "metadata": {},
   "source": [
    "1. https://iambeginnerdeveloper.tistory.com/41\n",
    "2. https://github.com/miinkang/AI_Project_AIFFEL/blob/main/%5BGD-12%5Dtransformer_chatbot.ipynb\n",
    "3. https://github.com/hongdune/aiffel/blob/master/GD12_chatbot.ipynb\n",
    "4. https://stackoverflow.com/questions/7197315/5-maximum-values-in-a-python-dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
