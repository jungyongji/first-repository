{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007be1e8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64503cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c695075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c1cb5",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e72ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getenv('HOME')+'/aiffel/transformer_chatbot/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e0a671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path +'/ChatbotData.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53c12f",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8306176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba5adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf68b721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:,:2]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c3226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡!\n",
      "A : 하루가 또 가네요.\n",
      "\n",
      "Q : 1지망 학교 떨어졌어\n",
      "A : 위로해 드립니다.\n",
      "\n",
      "Q : 3박4일 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : 3박4일 정도 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살이 찌푸려지죠.\n",
      "\n",
      "Q : SD카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SD카드 안돼\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Q : SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n",
      "Q : SNS 시간낭비인데 자꾸 보게됨\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Q :', data['Q'][i])\n",
    "    print('A :', data['A'][i])    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fe7059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>가족들과 상의해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>공시 준비 힘들어</td>\n",
       "      <td>잘 될 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>돈 벌고 싶어</td>\n",
       "      <td>많이 벌수록 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>로또 번호 알려줘</td>\n",
       "      <td>알면 제가 하죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>마음이 울적해</td>\n",
       "      <td>거리를 걸어보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>착해서 잘해주는 건지 좋아하는 건지</td>\n",
       "      <td>헷갈린다고 말해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>첫 눈에 반하는게 가능해?</td>\n",
       "      <td>당연히 가능하죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>첫사랑 생각나</td>\n",
       "      <td>지금의 사랑에 충실하세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>커플여행이 나을까 그냥 우리끼리 갈까?</td>\n",
       "      <td>저는 둘이 가는 게 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Q                A\n",
       "196               고양이 키우고 싶어     가족들과 상의해보세요.\n",
       "235                공시 준비 힘들어         잘 될 거예요.\n",
       "1294                 돈 벌고 싶어      많이 벌수록 좋아요.\n",
       "1445               로또 번호 알려줘        알면 제가 하죠.\n",
       "1481                 마음이 울적해       거리를 걸어보세요.\n",
       "...                      ...              ...\n",
       "11642    착해서 잘해주는 건지 좋아하는 건지     헷갈린다고 말해보세요.\n",
       "11649         첫 눈에 반하는게 가능해?        당연히 가능하죠.\n",
       "11658                첫사랑 생각나   지금의 사랑에 충실하세요.\n",
       "11732  커플여행이 나을까 그냥 우리끼리 갈까?  저는 둘이 가는 게 좋아요.\n",
       "11819         훔쳐보는 것도 눈치 보임.    훔쳐보는 거 티나나봐요.\n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['Q'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ba24e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가끔 뭐하는지 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가스불 켜놓고 나온거 같아</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.</td>\n",
       "      <td>맘고생 많았어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>화이트데이에 고백할까요?</td>\n",
       "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11809</th>\n",
       "      <td>확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?</td>\n",
       "      <td>그 사람을 위해서는 그러면 안돼요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Q                                    A\n",
       "3                       3박4일 정도 놀러가고 싶다                          여행은 언제나 좋죠.\n",
       "6                               SD카드 안돼                   다시 새로 사는 게 마음 편해요.\n",
       "9                     SNS 시간낭비인데 자꾸 보게됨                        시간을 정하고 해보세요.\n",
       "12                          가끔 뭐하는지 궁금해                        그 사람도 그럴 거예요.\n",
       "18                       가스불 켜놓고 나온거 같아                  빨리 집에 돌아가서 끄고 나오세요.\n",
       "...                                 ...                                  ...\n",
       "11806         혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.                            맘고생 많았어요.\n",
       "11807                     화이트데이에 고백할까요?            선물을 주면서 솔직하고 당당하게 고백해보세요.\n",
       "11809  확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?                  그 사람을 위해서는 그러면 안돼요.\n",
       "11816                 회식하는데 나만 챙겨줘. 썸임?  호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11822                        힘들어서 결혼할까봐                   도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[4044 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['A'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5aae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 56\n",
      "문장의 평균 길이: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1381028093.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in data['Q']:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(data['Q']))\n",
    "\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in data['Q']:   # 중복이 제거된 코퍼스 기준\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363a3a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 76\n",
      "문장의 평균 길이: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/2128007342.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in data['A']:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(data['A']))\n",
    "\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in data['A']:   # 중복이 제거된 코퍼스 기준\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e29ee7",
   "metadata": {},
   "source": [
    "## Preprocessing and Tokeninzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea95e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!가-힣ㄱ-ㅎㅏ-ㅣ0-9]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5381c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "max = 0\n",
    "for i in data['A']:\n",
    "    length = len(preprocess_sentence(i))\n",
    "    if max_len < length: max_len = length\n",
    "    temp.append(preprocess_sentence(i))\n",
    "    \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13dbc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(row_file):\n",
    "    que_corpus = []\n",
    "    ans_corpus = []\n",
    "    \n",
    "    for i in range(0, len(row_file)):\n",
    "        mecab = Mecab()\n",
    "        \n",
    "        que, ans = row_file.loc[i]\n",
    "        \n",
    "        que = preprocess_sentence(que)\n",
    "        que = mecab.morphs(que)\n",
    "        \n",
    "        ans = preprocess_sentence(ans)\n",
    "        ans = mecab.morphs(ans)\n",
    "        \n",
    "        if len(que) < 20 and len(ans) < 20 : # 길이의 75퍼센타일 \n",
    "            if que not in que_corpus:\n",
    "                if ans not in ans_corpus: #소스와 타겟별 중복 검사\n",
    "                    que_corpus.append(que)\n",
    "                    ans_corpus.append(ans)\n",
    "    \n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205a4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = build_corpus(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92601448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', 'ㅠㅠ'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2fa4790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['하루', '가', '또', '가', '네요', '.'],\n",
       " ['위로', '해', '드립니다', '.'],\n",
       " ['여행', '은', '언제나', '좋', '죠', '.'],\n",
       " ['눈살', '이', '찌푸려', '지', '죠', '.'],\n",
       " ['다시', '새로', '사', '는', '게', '마음', '편해요', '.'],\n",
       " ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.'],\n",
       " ['시간', '을', '정하', '고', '해', '보', '세요', '.'],\n",
       " ['자랑', '하', '는', '자리', '니까요', '.'],\n",
       " ['그', '사람', '도', '그럴', '거', '예요', '.'],\n",
       " ['혼자', '를', '즐기', '세요', '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931d252",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eebd4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_bin_path = path + '/ko.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06a301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(ko_bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "639bed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    toks = sentence\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(toks)\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "\n",
    "    except:   # 단어장에 없는 단어\n",
    "        return sentence\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok is _from: res.append(_to)\n",
    "        else: res.append(tok)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a62f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['12', '시', '땡', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4fc408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['12', '시가', '땡', '!']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_sub(temp, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc38bc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7520\n",
      "7520\n"
     ]
    }
   ],
   "source": [
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9b0fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/859389102.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57be6473d77341638b238145a20a64a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = lexical_sub(que_corpus[i], word2vec)\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a3e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/2512862008.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cbf505d1a04f6db616faaab25ecdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = lexical_sub(ans_corpus[i], word2vec)\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c8c978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1073649924.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b679c691cebe44d3ae362cd6b1b16335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0e901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54da0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1283461507.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9d1610adc348e1a382cd469458d00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = lexical_sub(que_corpus[i], word2vec)\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec43a357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/2512862008.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9036a8f72c04645931254770c0aede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/503012188.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = lexical_sub(ans_corpus[i], word2vec)\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20d79c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1073649924.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff523af9c0744b0cb93eddf851079250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4387db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45120\n",
      "45120\n"
     ]
    }
   ],
   "source": [
    "print(len(src_corpus))\n",
    "print(len(tgt_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a89736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시가', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '살', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '강하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', '...'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '으며', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '기에', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금하', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '으며']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fab6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data = []\n",
    "\n",
    "for sen in tgt_corpus:\n",
    "    sen = [\"<start>\"] + sen + [\"<end>\"]\n",
    "    que_data.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef4fcf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '.', '<end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '.', '<end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', '<end>'],\n",
       " ['<start>', '눈살', '이', '찌푸려', '지', '죠', '.', '<end>'],\n",
       " ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '.', '<end>'],\n",
       " ['<start>', '잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.', '<end>'],\n",
       " ['<start>', '시간', '을', '정하', '고', '해', '보', '세요', '.', '<end>'],\n",
       " ['<start>', '자랑', '하', '는', '자리', '니까요', '.', '<end>'],\n",
       " ['<start>', '그', '사람', '도', '그럴', '거', '예요', '.', '<end>'],\n",
       " ['<start>', '혼자', '를', '즐기', '세요', '.', '<end>']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959af03",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "588bb82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90240"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = que_data + src_corpus\n",
    "\n",
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "938c7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.concatenate(total_data).tolist()\n",
    "counter = Counter(words)\n",
    "counter = counter.most_common(30000-2)\n",
    "vocab = ['<pad>', '<unk>'] + [key for key, _ in counter]\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0518d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', '.', '<start>', '<end>', '이', '는', '하', '을', '가']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(word_to_index))\n",
    "sorted(word_to_index, key=word_to_index.get)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "690a5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1611217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<unk>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf6e3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fff68af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = vectorize(src_corpus, word_to_index)\n",
    "dec_train = vectorize(que_data, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd137563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45120\n",
      "45120\n",
      "[2412, 2148, 3172, 106]\n",
      "[3, 276, 9, 135, 9, 41, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_train))\n",
    "print(len(dec_train))\n",
    "print(enc_train[0])\n",
    "print(dec_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5be7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = keras.preprocessing.sequence.pad_sequences(enc_train,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=20)\n",
    "\n",
    "dec_train = keras.preprocessing.sequence.pad_sequences(dec_train,\n",
    "                                                       value=word_to_index[\"<pad>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063e7c7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f63f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db1ee5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f66d8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fdaad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c6c7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.dec_self_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67e79089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f2a46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "610549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a90fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "335e3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11b3c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=6,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=30000,\n",
    "    tgt_vocab_size=30000,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f63a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8055da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fad56657",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]\n",
    "    gold = tgt[:, 1:]\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbc396",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d044e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/1616849634.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c16429efe204390872eb25baf913773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d65b1a6b444fb39b1b6667ef873d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab0c2dbfd646b9b4a17820a481a767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e05a3c66bb49929c5cc48a95044c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bccf4b14994ea79ef013f3e63bdc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f40c014fc43424ea244ee3742251199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bfd376762b4e829c576665842f5c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47412051b8944d9885cc0c4036f496de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f9ad0e09b94980ab8eb9033c60739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f53434aa084e61b70ab0a433d47a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83869c07611c4e87a176d8c4126c9ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ab0ed74b5b4ca5a5e2a7962bbdd432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97333b6a4514073ac83062aa0bb93cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5882d520120e4498955370e1a1bd67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0e8df9d51f479fa8f9833ce79a846c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1214647953a546e69598b9b21d9dae36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6024586e4f34375ab567bc92d916476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3be8b1dfd94668a6f6756c3f9d795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cff4dbb37c04555b64f68325732669d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184fea6a378347008ed499c6fc45d742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a06fe7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28563e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8967bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, model):\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    pieces = mecab.morphs(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for sen in pieces:\n",
    "        sen= get_encoded_sentence(sen, word_to_index)\n",
    "        tokens.append(sen)\n",
    "    \n",
    "    _input = keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=20)\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([word_to_index[\"<start>\"]], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if word_to_index[\"<end>\"] == predicted_id:\n",
    "            result = get_decoded_sentence(ids, index_to_word)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = get_decoded_sentence(ids, index_to_word)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f26c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "883213a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ['지루하다, 놀러가고 싶어.',\n",
    "               '오늘 일찍 일어났더니 피곤하다.',\n",
    "               '간만에 여자친구랑 데이트 하기로 했어.',\n",
    "               '집에 있는다는 소리야.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23065761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  지루하다, 놀러가고 싶어.\n",
      "답변 :  서 도 그 도 좋 은 방법 이 에요 .\n",
      "원문 :  오늘 일찍 일어났더니 피곤하다.\n",
      "답변 :  은 기억 에 좋 겠 네요 .\n",
      "원문 :  간만에 여자친구랑 데이트 하기로 했어.\n",
      "답변 :  만 의 시간 이 필요 하 겠 네요 .\n",
      "원문 :  집에 있는다는 소리야.\n",
      "답변 :  를 상대 를 상대 를 헷갈리 상대 요 .\n"
     ]
    }
   ],
   "source": [
    "for sen in sample_text:\n",
    "    print('원문 : ', sen)\n",
    "    print('답변 : ', translate(sen, transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfe282",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817c742",
   "metadata": {},
   "source": [
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?  \n",
    " - **챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 4.3만개 가량의 훈련데이터셋이 구축되었다.**  \n",
    " \n",
    " \n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?  \n",
    " - **과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.**  \n",
    " \n",
    " \n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?  \n",
    " - **주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하지는 못하지만, 얼추 문장 구성은 완료되었다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5475d19",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd54ece",
   "metadata": {},
   "source": [
    "1. https://iambeginnerdeveloper.tistory.com/41\n",
    "2. https://github.com/miinkang/AI_Project_AIFFEL/blob/main/%5BGD-12%5Dtransformer_chatbot.ipynb\n",
    "3. https://github.com/hongdune/aiffel/blob/master/GD12_chatbot.ipynb\n",
    "4. https://stackoverflow.com/questions/7197315/5-maximum-values-in-a-python-dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
